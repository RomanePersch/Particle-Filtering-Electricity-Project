{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=5, micro=2, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vérifier qu'on est bien sur Python 3.5\n",
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_extraction_script_module2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp = data_extraction_script_module2.Temperatures()\n",
    "tp.get_temperatures('C:/Users/roman/Desktop/ENSAE 3A/HMM et Monte Carlo/Donnees temperature/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hour</th>\n",
       "      <th>00:00</th>\n",
       "      <th>03:00</th>\n",
       "      <th>06:00</th>\n",
       "      <th>09:00</th>\n",
       "      <th>12:00</th>\n",
       "      <th>15:00</th>\n",
       "      <th>18:00</th>\n",
       "      <th>21:00</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.012821</td>\n",
       "      <td>2.725641</td>\n",
       "      <td>2.317949</td>\n",
       "      <td>2.625641</td>\n",
       "      <td>4.176923</td>\n",
       "      <td>4.641026</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.753846</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.553846</td>\n",
       "      <td>2.415385</td>\n",
       "      <td>2.143590</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>4.584615</td>\n",
       "      <td>4.387179</td>\n",
       "      <td>2.282051</td>\n",
       "      <td>1.587179</td>\n",
       "      <td>2011-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>-0.351282</td>\n",
       "      <td>-0.892308</td>\n",
       "      <td>-0.023077</td>\n",
       "      <td>2.430769</td>\n",
       "      <td>2.689744</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.164103</td>\n",
       "      <td>2011-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.248718</td>\n",
       "      <td>-0.705128</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.492308</td>\n",
       "      <td>1.961538</td>\n",
       "      <td>2.661538</td>\n",
       "      <td>1.223077</td>\n",
       "      <td>0.671795</td>\n",
       "      <td>2011-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.402564</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>5.351282</td>\n",
       "      <td>6.128205</td>\n",
       "      <td>5.682051</td>\n",
       "      <td>6.064103</td>\n",
       "      <td>2011-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hour     00:00     03:00     06:00     09:00     12:00     15:00     18:00  \\\n",
       "0     3.012821  2.725641  2.317949  2.625641  4.176923  4.641026  3.333333   \n",
       "1     2.553846  2.415385  2.143590  2.566667  4.584615  4.387179  2.282051   \n",
       "2     0.653846 -0.351282 -0.892308 -0.023077  2.430769  2.689744  0.700000   \n",
       "3    -0.248718 -0.705128 -0.666667 -0.492308  1.961538  2.661538  1.223077   \n",
       "4     0.476923  0.402564  0.435897  1.933333  5.351282  6.128205  5.682051   \n",
       "\n",
       "hour     21:00        date  \n",
       "0     2.753846  2011-01-01  \n",
       "1     1.587179  2011-01-02  \n",
       "2    -0.164103  2011-01-03  \n",
       "3     0.671795  2011-01-04  \n",
       "4     6.064103  2011-01-05  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\Desktop\\ENSAE 3A\\HMM et Monte Carlo\\data_extraction_script_module2.py:144: UserWarning: WARNING : There is more than 365 days or less than 365 days in dataframe\n",
      "  warnings.warn(\"WARNING : There is more than 365 days or less than 365 days in dataframe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historique_consommation_INST_2012/Historique_consommation_INST_2012.xls\n",
      "Number of rows 366\n"
     ]
    }
   ],
   "source": [
    "elec = data_extraction_script_module2.Electricity()\n",
    "elec.get_electricity_data(\"C:/Users/roman/Desktop/ENSAE 3A/HMM et Monte Carlo/Donnees electricite/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Type de données</th>\n",
       "      <th>00:30</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:30</th>\n",
       "      <th>02:00</th>\n",
       "      <th>02:30</th>\n",
       "      <th>03:00</th>\n",
       "      <th>03:30</th>\n",
       "      <th>04:00</th>\n",
       "      <th>...</th>\n",
       "      <th>20:00</th>\n",
       "      <th>20:30</th>\n",
       "      <th>21:00</th>\n",
       "      <th>21:30</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:30</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:30</th>\n",
       "      <th>24:00</th>\n",
       "      <th>Day_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>Définitives</td>\n",
       "      <td>70671.0</td>\n",
       "      <td>68887.0</td>\n",
       "      <td>69045.0</td>\n",
       "      <td>68830.0</td>\n",
       "      <td>68143.0</td>\n",
       "      <td>65950.0</td>\n",
       "      <td>64343.0</td>\n",
       "      <td>62676.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70926.0</td>\n",
       "      <td>70532.0</td>\n",
       "      <td>69433.0</td>\n",
       "      <td>68257.0</td>\n",
       "      <td>67221.0</td>\n",
       "      <td>68287.0</td>\n",
       "      <td>70497.0</td>\n",
       "      <td>69320.0</td>\n",
       "      <td>69062.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>Définitives</td>\n",
       "      <td>67537.0</td>\n",
       "      <td>65099.0</td>\n",
       "      <td>65152.0</td>\n",
       "      <td>64785.0</td>\n",
       "      <td>64478.0</td>\n",
       "      <td>62594.0</td>\n",
       "      <td>61319.0</td>\n",
       "      <td>60084.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75851.0</td>\n",
       "      <td>74972.0</td>\n",
       "      <td>73480.0</td>\n",
       "      <td>71938.0</td>\n",
       "      <td>70788.0</td>\n",
       "      <td>71380.0</td>\n",
       "      <td>73374.0</td>\n",
       "      <td>72138.0</td>\n",
       "      <td>71897.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>Définitives</td>\n",
       "      <td>70483.0</td>\n",
       "      <td>68325.0</td>\n",
       "      <td>68628.0</td>\n",
       "      <td>68694.0</td>\n",
       "      <td>68715.0</td>\n",
       "      <td>67143.0</td>\n",
       "      <td>66038.0</td>\n",
       "      <td>65140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86672.0</td>\n",
       "      <td>84611.0</td>\n",
       "      <td>82317.0</td>\n",
       "      <td>80219.0</td>\n",
       "      <td>78181.0</td>\n",
       "      <td>78450.0</td>\n",
       "      <td>80072.0</td>\n",
       "      <td>78675.0</td>\n",
       "      <td>78509.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>Définitives</td>\n",
       "      <td>76712.0</td>\n",
       "      <td>74313.0</td>\n",
       "      <td>74466.0</td>\n",
       "      <td>74199.0</td>\n",
       "      <td>74196.0</td>\n",
       "      <td>72428.0</td>\n",
       "      <td>71160.0</td>\n",
       "      <td>70052.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88879.0</td>\n",
       "      <td>86587.0</td>\n",
       "      <td>84053.0</td>\n",
       "      <td>81787.0</td>\n",
       "      <td>79995.0</td>\n",
       "      <td>80119.0</td>\n",
       "      <td>81749.0</td>\n",
       "      <td>80214.0</td>\n",
       "      <td>79953.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Définitives</td>\n",
       "      <td>78121.0</td>\n",
       "      <td>75826.0</td>\n",
       "      <td>75627.0</td>\n",
       "      <td>75486.0</td>\n",
       "      <td>75425.0</td>\n",
       "      <td>73532.0</td>\n",
       "      <td>72180.0</td>\n",
       "      <td>71197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85901.0</td>\n",
       "      <td>83329.0</td>\n",
       "      <td>80561.0</td>\n",
       "      <td>78396.0</td>\n",
       "      <td>76036.0</td>\n",
       "      <td>75946.0</td>\n",
       "      <td>77336.0</td>\n",
       "      <td>75885.0</td>\n",
       "      <td>75385.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Type de données    00:30    01:00    01:30    02:00    02:30  \\\n",
       "0  2011-01-01     Définitives  70671.0  68887.0  69045.0  68830.0  68143.0   \n",
       "1  2011-01-02     Définitives  67537.0  65099.0  65152.0  64785.0  64478.0   \n",
       "2  2011-01-03     Définitives  70483.0  68325.0  68628.0  68694.0  68715.0   \n",
       "3  2011-01-04     Définitives  76712.0  74313.0  74466.0  74199.0  74196.0   \n",
       "4  2011-01-05     Définitives  78121.0  75826.0  75627.0  75486.0  75425.0   \n",
       "\n",
       "     03:00    03:30    04:00    ...       20:00    20:30    21:00    21:30  \\\n",
       "0  65950.0  64343.0  62676.0    ...     70926.0  70532.0  69433.0  68257.0   \n",
       "1  62594.0  61319.0  60084.0    ...     75851.0  74972.0  73480.0  71938.0   \n",
       "2  67143.0  66038.0  65140.0    ...     86672.0  84611.0  82317.0  80219.0   \n",
       "3  72428.0  71160.0  70052.0    ...     88879.0  86587.0  84053.0  81787.0   \n",
       "4  73532.0  72180.0  71197.0    ...     85901.0  83329.0  80561.0  78396.0   \n",
       "\n",
       "     22:00    22:30    23:00    23:30    24:00  Day_type  \n",
       "0  67221.0  68287.0  70497.0  69320.0  69062.0         6  \n",
       "1  70788.0  71380.0  73374.0  72138.0  71897.0         7  \n",
       "2  78181.0  78450.0  80072.0  78675.0  78509.0         0  \n",
       "3  79995.0  80119.0  81749.0  80214.0  79953.0         1  \n",
       "4  76036.0  75946.0  77336.0  75885.0  75385.0         1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend 15:00 pour tester (au moins pas de problèmes de changement d'heure et autre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create date series only to keep track of the dates\n",
    "date_ts = elec.date_ts()\n",
    "#Create Day Type series\n",
    "daytype_ts = elec.daytype_ts()\n",
    "#Create temperature time series at the chosen hour\n",
    "tp_ts = tp.temperature_ts('15:00')\n",
    "#Create electricity time series at the chosen hour\n",
    "elec_ts = elec.elec_ts('15:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_heat = 14.4714351637\n",
      "kappa = [ 0.41312159  1.1040987   1.08632684  0.22836172  0.2321909   1.16154018\n",
      "  2.27696106  1.49739901] , sum kappa verif : 8.0\n",
      "sigma2 =  4.30397970916e+42\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "#Take arbitrary parameters\n",
    "u_heat = np.random.normal(size=1, loc = 14, scale = 1)[0] #loc = mean / scale = standard deviation /!\\\n",
    "print(\"u_heat =\", u_heat)\n",
    "number_of_daytypes = len(set(elec.df.Day_type))\n",
    "kappa = (np.random.dirichlet(size = 1, alpha = [1]*number_of_daytypes)[0])*number_of_daytypes\n",
    "print(\"kappa =\", kappa, \", sum kappa verif :\", sum(kappa))\n",
    "sigma2 = 1 / (np.random.gamma(size = 1, shape = 0.01, scale = 100)[0]) \n",
    "print('sigma2 = ', sigma2) #Très grand...\n",
    "sigma2_s_param = 1 / (np.random.gamma(size = 1, shape = 0.01, scale = 100)[0])\n",
    "sigma2_g_param = 1 / (np.random.gamma(size = 1, shape = 0.01, scale = 100)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Particle_Filtering_Model(object):\n",
    "    \n",
    "    def __init__(self,u_heat,kappa,sigma2, sigma2_s_param, sigma2_g_param, nb_particles, len_filtering):\n",
    "        \"\"\"constructor\n",
    "        u_heat,kappa,sigma2, sigma2_s_param, sigma2_g_param : float which define the fixed parameters of the model\"\"\"\n",
    "        import numpy as np\n",
    "        from scipy.stats import truncnorm\n",
    "        import math\n",
    "        #Define the fixed parameters theta of the model\n",
    "        self.u_heat = u_heat\n",
    "        self.kappa = kappa\n",
    "        self.sigma2 = sigma2\n",
    "        self.sigma2_s_param = sigma2_s_param\n",
    "        self.sigma2_g_param = sigma2_g_param\n",
    "        #Define the number of particles we want to simulate and the length of the filtering process (from date 0 to date n0)\n",
    "        self.nb_particles = nb_particles\n",
    "        self.len_filtering = len_filtering\n",
    "        #Initialize the numpy arrays of x, s, g_heat, sigma_s and sigma_g\n",
    "        self.s = np.zeros((len_filtering, nb_particles))\n",
    "        self.sigma_s = np.zeros((len_filtering, nb_particles))\n",
    "        self.sigma_g = np.zeros((len_filtering, nb_particles))\n",
    "        self.g_heat = np.zeros((len_filtering, nb_particles))\n",
    "        self.x = np.zeros((len_filtering, nb_particles))\n",
    "        #Initialize the weights\n",
    "        self.lw = np.zeros((len_filtering, nb_particles))\n",
    "        self.w = np.zeros((len_filtering, nb_particles))\n",
    "    \n",
    "    def exp_and_normalize(self, lw):\n",
    "        \"\"\"Computes the normalized weights from the non normalized log weights\n",
    "        lw : vector of the log weights (row numpy array)\"\"\"\n",
    "        w = np.exp(lw - max(lw)) #np.exp Calculates the exponential of all elements in the input array.\n",
    "        res = w / sum(w)\n",
    "        return(res)\n",
    "    \n",
    "    def compute_log_g_y(self, x, elec):\n",
    "        \"\"\" Computes the log of the likelihood function \n",
    "        x : float\n",
    "        elec : float \"\"\"\n",
    "        res = -((elec-x)**2)/(2*self.sigma2)\n",
    "        return(res)\n",
    "    \n",
    "    def vcompute_log_g_y(self, x_vector, elec):\n",
    "        \"\"\" Computes the log of the likelihood function for all particles at the same time\n",
    "        x : row of numpy array (vector of the values of x for each particle at the considered time)\n",
    "        elec : float (value of the observed electricty load y at the considered time) \"\"\"\n",
    "        vectorized_function = np.vectorize(self.compute_log_g_y, excluded=['elec'])\n",
    "        return(vectorized_function(x_vector, elec))\n",
    "    \n",
    "    def compute_x(self, s, g_heat, temperature, daytype):\n",
    "        \"\"\" Computes the value of x for each particle at a specific time t\n",
    "        Parameters :\n",
    "        -s are g_heat are row vectors (value of s and g_heat for each particle)\n",
    "        -temperature and daytype are constants (observed data at time t)\n",
    "        Returns a row vector\"\"\"\n",
    "        x_season = self.kappa[daytype]*s\n",
    "        if temperature < u_heat :\n",
    "            x_heat = (temperature-self.u_heat)*g_heat\n",
    "        else :\n",
    "            x_heat = np.zeros(g_heat.shape)\n",
    "        x = x_season + x_heat\n",
    "        return(x)\n",
    "    \n",
    "    def initialization_SIS_withoutMCMC(self, temperature_ts, daytype_ts):\n",
    "        \"\"\" Initialization of the values of s, g_heat, sigma_s and sigma_g (and hence x) using the prior distributions of the article\n",
    "        This initialization could also be done using a first MCMC Gibbs sampling step\"\"\"\n",
    "        self.s[0,] = truncnorm.rvs(a = 0,b = math.inf, loc= 0, scale = 10**4, size=self.nb_particles)#loc = mean / scale = standard deviation /!\\\n",
    "        self.sigma_s[0,] =(1 / (np.random.gamma(size = self.nb_particles, shape = 0.01, scale = 100)))**0.5\n",
    "        self.sigma_g[0,] = (1 / (np.random.gamma(size = self.nb_particles, shape = 0.01, scale = 100)))**0.5\n",
    "        self.g_heat[0,] = truncnorm.rvs(a = - math.inf,b = 0, loc= 0, scale = 10**4, size=self.nb_particles)#loc = mean / scale = standard deviation /!\\\n",
    "        self.x[0,] = self.compute_x(s = self.s[0,], g_heat = self.g_heat[0,], temperature = temperature_ts[0], daytype = daytype_ts[0])\n",
    "        \n",
    "    def sample_new_sigma_g(self, sigma_g_prev):\n",
    "        \"\"\" Simulates the current sigma_g given the previous sigma_g\n",
    "        Parameters :\n",
    "        -sigma_g_prev : float \n",
    "        Return a float\"\"\"\n",
    "        #see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.truncnorm.html\n",
    "        #/!\\ The standard form of this distribution is a STANDARD normal truncated to the range [a, b] — \n",
    "        #notice that a and b are defined over the domain of the STANDARD normal. \n",
    "        #To convert clip values for a specific mean and standard deviation :\n",
    "        my_mean = 0\n",
    "        my_std = (self.sigma2_g_param)**0.5\n",
    "        myclip_a = - sigma_g_prev\n",
    "        myclip_b = math.inf\n",
    "        a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "        error = truncnorm.rvs(a = a, b = b, loc= my_mean, scale = my_std, size=1)[0]#loc = mean / scale = standard deviation\n",
    "        res = sigma_g_prev + error\n",
    "        return(res)\n",
    "    \n",
    "    def vsample_new_sigma_g(self, sigma_g_prev_vector):\n",
    "        \"\"\" Simulates the current sigma_g for each particle given the previous sigma_g for each particle\n",
    "        Parameters : \n",
    "        -sigma_g_prev : vector (row of a numpy array)\n",
    "        Returns a row vector\"\"\"\n",
    "        vectorized_function = np.vectorize(self.sample_new_sigma_g)\n",
    "        return(vectorized_function(sigma_g_prev_vector))\n",
    "    \n",
    "    def sample_new_sigma_s(self, sigma_s_prev):\n",
    "        \"\"\" Simulates the current sigma_s given the previous sigma_s\n",
    "        Parameters : \n",
    "        -sigma_s_prev : float \n",
    "        Returns a float \"\"\"\n",
    "        my_mean = 0\n",
    "        my_std = (self.sigma2_s_param)**0.5\n",
    "        myclip_a = - sigma_s_prev\n",
    "        myclip_b = math.inf\n",
    "        a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "        error = truncnorm.rvs(a = a, b = b, loc= my_mean, scale = my_std, size=1)[0]#loc = mean / scale = standard deviation\n",
    "        res = sigma_s_prev + error\n",
    "        return(res)\n",
    "    \n",
    "    def vsample_new_sigma_s(self, sigma_s_prev_vector) :\n",
    "        \"\"\" Simulates the current sigma_s for each particle given the previous sigma_s for each particle\n",
    "        Parameters : \n",
    "        -sigma_s_prev : vector (row of a numpy array) \n",
    "        Returns a row vector \"\"\"\n",
    "        vectorized_function = np.vectorize(self.sample_new_sigma_s)\n",
    "        return(vectorized_function(sigma_s_prev_vector))\n",
    "    \n",
    "    def sample_new_g_heat(self, g_heat_prev, sigma_g_current):\n",
    "        \"\"\" Simulates the current g_heat given the previous g_heat and the current sigma_g\n",
    "        Parameters :\n",
    "        -g_heat_prev : float\n",
    "        -sigma_g_current : float\n",
    "        Returns a float \"\"\"\n",
    "        my_mean = 0\n",
    "        my_std = sigma_g_current\n",
    "        myclip_a = - math.inf\n",
    "        myclip_b = -g_heat_prev\n",
    "        a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "        error = truncnorm.rvs(a = a, b = b, loc= my_mean, scale = my_std, size=1)#loc = mean / scale = standard deviation\n",
    "        res = g_heat_prev + error\n",
    "        return(res)\n",
    "    \n",
    "    def vsample_new_g_heat(self, g_heat_prev, sigma_g_current):\n",
    "        \"\"\" Simulates the current g_heat for each particle given the previous g_heat for each particle and the current \n",
    "        sigma_g for each particle.\n",
    "        Parameters :\n",
    "        -g_heat_prev :row of a numpy array (size =  1 x nb_particles)\n",
    "        -sigma_g_current : row of a numpy array (size = 1 x nb_particles)\n",
    "        Returns a row vector\"\"\"\n",
    "        nb_part = len(g_heat_prev)\n",
    "        g_heat_new =  np.zeros((1, nb_part))\n",
    "        for j in range(nb_part):\n",
    "            g_heat_new[0,j] = self.sample_new_g_heat(g_heat_prev[j], sigma_g_current[j])\n",
    "        return(g_heat_new)\n",
    "    \n",
    "    def sample_new_s(self, s_prev, sigma_s_current):\n",
    "        \"\"\" Simulates the current s given the previous s and the current sigma_s\n",
    "        Parameters :\n",
    "        -s_prev : float\n",
    "        -sigma_s_current : float\"\"\"\n",
    "        my_mean = 0\n",
    "        my_std = sigma_s_current\n",
    "        myclip_a = -s_prev\n",
    "        myclip_b = math.inf\n",
    "        a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "        error = truncnorm.rvs(a = a, b = b, loc= my_mean, scale = my_std, size=1)#loc = mean / scale = standard deviation\n",
    "        res = s_prev + error\n",
    "        return(res)\n",
    "    \n",
    "    def vsample_new_s(self, s_prev, sigma_s_current):\n",
    "        \"\"\" Simulates the current s for each particle given the previous s for each particle and the current \n",
    "        sigma_s for each particle.\n",
    "        Parameters :\n",
    "        -s_prev :row of a numpy array (size =  1 x nb_particles)\n",
    "        -sigma_s_current : row of a numpy array (size = 1 x nb_particles)\"\"\"\n",
    "        nb_part = len(s_prev)\n",
    "        s_new =  np.zeros((1, nb_part))\n",
    "        for j in range(nb_part):\n",
    "            s_new[0,j] = self.sample_new_s(s_prev[j], sigma_s_current[j])\n",
    "        return(s_new)\n",
    "    \n",
    "    def sample_from_transition(self, s_prev, g_heat_prev, sigma_s_prev, sigma_g_prev):\n",
    "        \"\"\" Samples the vector x, s, g_heat, sigma2_s, sigma2_g at time n from transition density\n",
    "        Given s, g_heat, sigma2_s, sigma2_g at time (n-1)\n",
    "        Parameters :\n",
    "        s_prev, g_heat_prev, sigma2_s_prev, sigma2_g_prev : row of numpy array (size = 1 x nb_particles)\"\"\"\n",
    "        sigma_g_current = self.vsample_new_sigma_g(sigma_g_prev)\n",
    "        sigma_s_current = self.vsample_new_sigma_s(sigma_s_prev)\n",
    "        g_heat_current = self.vsample_new_g_heat(g_heat_prev, sigma_g_current)\n",
    "        s_current = self.vsample_new_s(s_prev, sigma_s_current)\n",
    "        return(s_current, g_heat_current, sigma_s_current, sigma_g_current)\n",
    "    \n",
    "    def SIS_filter(self, elec_ts, temperature_ts, daytype_ts):\n",
    "        \"\"\" Sequential Importance Sampling for filtering\n",
    "        Given the set of parameters, simulate particles for each day until today (past)\"\"\"\n",
    "        #Initialization : time n = 0 \n",
    "        self.initialization_SIS_withoutMCMC(temperature_ts, daytype_ts)\n",
    "        self.lw[0,] = self.vcompute_log_g_y(x_vector = self.x[0,], elec = elec_ts[0]) #Compute the log weights at time 0\n",
    "        self.w[0,] = self.exp_and_normalize(self.lw[0,])#Compute the normalized weights at time 0\n",
    "        self.lw[0,] = np.log(self.w[0,]) #Compute the log of the normalized weights at time 0\n",
    "        #Main : at time n > 0\n",
    "        for n in range(1,self.len_filtering,1):\n",
    "            #1. Sample from transition density\n",
    "            self.s[n,], self.g_heat[n,], self.sigma_s[n,], self.sigma_g[n,] = self.sample_from_transition(s_prev = self.s[(n-1),], \n",
    "                                g_heat_prev = self.g_heat[(n-1),], sigma_s_prev = self.sigma_s[(n-1),], \n",
    "                                sigma_g_prev = self.sigma_g[(n-1),])\n",
    "            self.x[n,] = self.compute_x(s = self.s[n,], g_heat = self.g_heat[n,],  temperature = temperature_ts[n], daytype = daytype_ts[n])\n",
    "            #2. Update the weights\n",
    "            self.lw[n,] = self.lw[(n-1),] + self.vcompute_log_g_y(x_vector = self.x[n,], elec = elec_ts[n]) #Compute the log weights at time n\n",
    "            self.w[n,] = self.exp_and_normalize(self.lw[n,])#Compute the normalized weights at time 0\n",
    "            self.lw[n,] = np.log(self.w[n,]) #Compute the log of the normalized weights at time 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = Particle_Filtering_Model(u_heat,kappa,sigma2, sigma2_s_param, sigma2_g_param, nb_particles = 5, len_filtering = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.SIS_filter(elec_ts = elec_ts, temperature_ts = tp_ts, daytype_ts = daytype_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.40370449e+04,   3.08698842e+04,   5.50723635e+04,\n",
       "          2.46475107e+05,   2.53368893e+04],\n",
       "       [  6.67317832e+62,   5.13160960e+20,   2.19205510e+48,\n",
       "          3.25627363e+20,   6.09276705e+59],\n",
       "       [  1.34568956e+64,   3.87106371e+21,   3.91161596e+48,\n",
       "          1.85600285e+21,   2.50880778e+60]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2       ,  0.2       ,  0.2       ,  0.2       ,  0.2       ],\n",
       "       [ 0.        ,  0.49543165,  0.        ,  0.50456835,  0.        ],\n",
       "       [ 0.        ,  0.20441286,  0.        ,  0.79558714,  0.        ]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test.w[2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.90186048e+02,   8.64619225e+06,   3.54235969e+01,\n",
       "          2.02683302e+04,   3.70405320e+60],\n",
       "       [  1.34408444e+07,   1.43516727e+07,   5.09307073e+05,\n",
       "          1.56718662e+07,   3.70405320e+60],\n",
       "       [  1.69119078e+07,   9.90047393e+06,   2.55194264e+07,\n",
       "          3.08126163e+07,   3.70405320e+60]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sigma_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.63323932e+03,   7.33433662e+03,   1.20874381e+04,\n",
       "          1.55621734e+04,   9.10405775e+03],\n",
       "       [  6.34489896e+06,   6.58874946e+05,   7.74609059e+05,\n",
       "          1.53630450e+07,   4.06890014e+59],\n",
       "       [  7.55947444e+06,   7.28931217e+06,   3.22495918e+06,\n",
       "          4.15310155e+07,   6.07280730e+60]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.62873447e+63,   4.24083627e+18,   1.63872469e+47,\n",
       "          7.68573371e-02,   4.93979841e+01],\n",
       "       [  1.62873447e+63,   5.79525768e+20,   1.63872469e+47,\n",
       "          6.56772884e+19,   4.10667667e+20],\n",
       "       [  1.62873447e+63,   4.44115776e+20,   1.63872469e+47,\n",
       "          2.84427112e+20,   2.99747451e+19]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sigma_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.86374394e+02,  -1.44143388e+03,  -2.80250152e+03,\n",
       "         -2.14681437e+04,  -4.68678778e+02],\n",
       "       [ -6.61742278e+61,  -5.08873413e+19,  -2.17374010e+47,\n",
       "         -3.22906691e+19,  -3.36209968e+20],\n",
       "       [ -1.14218706e+63,  -3.28566037e+20,  -3.32008009e+47,\n",
       "         -1.57532799e+20,  -3.15656773e+20]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.g_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.4349792894921644e-42"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.compute_log_g_y(x = 10, elec = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.8811009432987727e-38"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.compute_log_g_y(x = 500, elec = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.43497929e-42,  -2.88110094e-38])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.vcompute_log_g_y(x_vector = [10, 500], elec = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
